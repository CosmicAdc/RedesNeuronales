{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90a4270",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b0/Logo_Universidad_Politécnica_Salesiana_del_Ecuador.png\" width=\"90%\">\n",
    "<h2>Práctica 1:\n",
    "    Redes neuronales</h2>\n",
    "<h3>Integrantes: Michelle Parraga, Andrés Alba </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52ecd1",
   "metadata": {},
   "source": [
    "b) modificar el cuaderno de tal manera que la red neuronal pueda aprender (clasificación perfecta) la compuerta \n",
    "XOR con 4 entradas. La primera capa debe tener 256 neuronas y la segunda capa 1 neurona. Mostrar como salida \n",
    "el dataframe con las columnas: “predicción” y “real”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b49fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#COMPUERTA XOR DE CUATRO ENTRADAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset: Entradas\n",
    "X = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 1],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 1, 1],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 1, 0, 1],#\n",
    "              [0, 1, 1, 0],#\n",
    "              [0, 1, 1, 1],\n",
    "              [1, 1, 1, 1],#\n",
    "              [1, 0, 0, 0],#\n",
    "              [1, 0, 0, 1],#\n",
    "              [1, 0, 1, 0],#\n",
    "              [1, 0, 1, 1],#\n",
    "              [1, 1, 0, 0],#\n",
    "              [1, 1, 0, 1],#\n",
    "              [1, 1, 1, 0],#\n",
    "              [1, 1, 1, 1],#\n",
    "              [0, 0, 0, 0],#\n",
    "              [0, 0, 0, 1],#\n",
    "              [0, 0, 1, 0],#\n",
    "              [0, 0, 1, 1],#\n",
    "              [0, 1, 0, 0],#\n",
    "              [0, 1, 0, 1],#\n",
    "              [0, 1, 1, 0],#\n",
    "              [0, 1, 1, 1],\n",
    "              [1, 1, 1, 1],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 0, 0, 1],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 1, 1],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 1, 0, 1],#\n",
    "              [0, 1, 1, 0],#\n",
    "              [0, 1, 1, 1],\n",
    "              [1, 1, 1, 1],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 0, 0, 1],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 1, 1],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 1, 0, 1],#\n",
    "              [0, 1, 1, 0],#\n",
    "              [0, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])#26\n",
    "\n",
    "# Salidas reales -> Aprendizaje Supervisado\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [0],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [0],#\n",
    "              [1],\n",
    "              [0],\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [1],#\n",
    "              [0],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [1],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [0],#\n",
    "              [0],#\n",
    "              [0],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [0],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [0],#\n",
    "              [0],#\n",
    "              [1],#\n",
    "              [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de828e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\" función sigmoide \"\"\"\n",
    "    fz=1/(1+np.exp(-z))\n",
    "    return fz\n",
    "\n",
    "def derivada(fz):\n",
    "    \"\"\" derivada de la función sigmoide \"\"\"\n",
    "    return fz*(1-fz)\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\" función tangente hiperbólica \"\"\"\n",
    "    return np.tanh(x)\n",
    " \n",
    "def tanh_derivada(x):\n",
    "    \"\"\" derivada de la función tangente hiperbólica \"\"\"\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdfffdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** ENTRADAS\n",
      "[[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]]\n",
      "********** PESOS PARA CAPA DE ENTRADA\n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822 -0.81532281\n",
      "  -0.62747958 -0.30887855 -0.20646505  0.07763347 -0.16161097  0.370439\n",
      "  -0.5910955   0.75623487 -0.94522481  0.34093502 -0.1653904   0.11737966\n",
      "  -0.71922612 -0.60379702  0.60148914  0.93652315 -0.37315164  0.38464523\n",
      "   0.7527783   0.78921333 -0.82991158 -0.92189043 -0.66033916  0.75628501\n",
      "  -0.80330633 -0.15778475  0.91577906  0.06633057  0.38375423 -0.36896874\n",
      "   0.37300186  0.66925134 -0.96342345  0.50028863  0.97772218  0.49633131\n",
      "  -0.43911202  0.57855866 -0.79354799 -0.10421295  0.81719101 -0.4127717\n",
      "  -0.42444932 -0.73994286 -0.96126608  0.35767107]\n",
      " [-0.57674377 -0.46890668 -0.01685368 -0.89327491  0.14823521 -0.70654285\n",
      "   0.17861107  0.39951672 -0.79533114 -0.17188802  0.38880032 -0.17164146\n",
      "  -0.90009308  0.07179281  0.32758929  0.02977822  0.88918951  0.17311008\n",
      "   0.80680383 -0.72505059 -0.72144731  0.61478258 -0.20464633 -0.66929161\n",
      "   0.85501716 -0.30446828  0.50162421  0.45199597  0.76661218  0.24734441\n",
      "   0.50188487 -0.30220332 -0.46014422  0.79177244 -0.14381762  0.92968009\n",
      "   0.326883    0.24339144 -0.77050805  0.89897852 -0.10017573  0.15677923\n",
      "  -0.18372639 -0.52594604  0.80675904  0.14735897 -0.99425935  0.23428983\n",
      "  -0.3467102   0.0541162   0.7718842  -0.28546048]\n",
      " [ 0.8170703   0.24672023 -0.96835751  0.85887447  0.38179384  0.9946457\n",
      "  -0.65531898 -0.7257285   0.86519093  0.39363632 -0.86799965  0.51092611\n",
      "   0.50775238  0.84604907  0.42304952 -0.75145808 -0.96023973 -0.94757803\n",
      "  -0.94338702 -0.50757786  0.7200559   0.07766213  0.10564396  0.68406178\n",
      "  -0.75165337 -0.44163264  0.17151854  0.9391915   0.12206044 -0.96270542\n",
      "   0.60126535 -0.53405145  0.61421039 -0.22427871  0.72708371  0.49424329\n",
      "   0.11248047 -0.72708955 -0.88016462 -0.75731309 -0.91089624 -0.78501174\n",
      "  -0.54858132  0.42597796  0.11943396 -0.97488804 -0.85605144  0.93455266\n",
      "   0.13620092 -0.59341353 -0.49534851  0.48765171]\n",
      " [-0.60914104  0.16271785  0.94003998  0.6936576  -0.52030448 -0.01246057\n",
      "   0.23991144  0.6579618  -0.68641721 -0.9628476  -0.85995571 -0.02730978\n",
      "   0.21265892  0.13770287 -0.36527518  0.97723231  0.15949044 -0.23971765\n",
      "   0.10189644  0.49066886  0.33846579 -0.47016088 -0.86733033 -0.2598316\n",
      "   0.25943501 -0.57965198  0.50551111 -0.86692704 -0.4793698   0.60950913\n",
      "  -0.61313143  0.27892176  0.04934062  0.84961594 -0.47340646 -0.86807782\n",
      "   0.47013193  0.54435606  0.81563171  0.86394414 -0.97209685 -0.53127583\n",
      "   0.23355671  0.89803264  0.90035224  0.11330638  0.8312127   0.28313242\n",
      "  -0.21998457 -0.02801867  0.20862097  0.09909584]]\n",
      "********** PESOS PARA CAPA DE SALIDA\n",
      "[[ 0.85236285]\n",
      " [ 0.83746687]\n",
      " [-0.21024877]\n",
      " [ 0.92652506]\n",
      " [-0.65208867]\n",
      " [-0.74734096]\n",
      " [-0.72984168]\n",
      " [ 0.01132433]\n",
      " [-0.95695039]\n",
      " [ 0.89594042]\n",
      " [ 0.65423094]\n",
      " [-0.96996204]\n",
      " [-0.64760749]\n",
      " [-0.33587285]\n",
      " [-0.73800631]\n",
      " [ 0.61898138]\n",
      " [-0.31052669]\n",
      " [ 0.88021496]\n",
      " [ 0.16402836]\n",
      " [ 0.75766397]\n",
      " [ 0.68946889]\n",
      " [ 0.81078464]\n",
      " [-0.08023947]\n",
      " [ 0.09269363]\n",
      " [ 0.59720718]\n",
      " [-0.4285623 ]\n",
      " [-0.01949295]\n",
      " [ 0.19822062]\n",
      " [-0.96893345]\n",
      " [ 0.18696282]\n",
      " [-0.1326473 ]\n",
      " [ 0.61472106]\n",
      " [-0.36951039]\n",
      " [ 0.78577742]\n",
      " [ 0.15571443]\n",
      " [-0.6319796 ]\n",
      " [ 0.57585847]\n",
      " [ 0.22406235]\n",
      " [-0.89218146]\n",
      " [-0.15961264]\n",
      " [ 0.35813767]\n",
      " [ 0.83720356]\n",
      " [-0.99919595]\n",
      " [ 0.9535183 ]\n",
      " [-0.24683937]\n",
      " [ 0.94756708]\n",
      " [ 0.2094322 ]\n",
      " [ 0.65769162]\n",
      " [ 0.14942301]\n",
      " [ 0.2561524 ]\n",
      " [-0.42884744]\n",
      " [ 0.17366668]]\n"
     ]
    }
   ],
   "source": [
    "# Construcción\n",
    "\n",
    "#Como paso opcional, definimos una seed (semilla), para tener los mismo resultados, e inicializamos de forma aleatoria los pesos.\n",
    "#La primera matriz de pesos tiene que ser de un tamaño fijo, en este caso (2,3) porque tenemos 2 valores de entrada \n",
    "#(es decir, 2 variables o características) y la siguiente capa tiene 3, entonces la salida tiene que tener la misma cantidad \n",
    "#de entradas que tiene la siguiente capa.\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#syn0=np.array([[0.1,0.3,0.5],\n",
    "#               [0.2,0.4,0.6]])\n",
    "#syn1=np.array([[0.7],\n",
    "#               [0.9],\n",
    "#               [0.11]])\n",
    "\n",
    "syn0 = 2*np.random.random((4,52)) - 1\n",
    "syn1 = 2*np.random.random((52,1)) - 1\n",
    "\n",
    "print('********** ENTRADAS')\n",
    "print(X)\n",
    "print('********** PESOS PARA CAPA DE ENTRADA')\n",
    "print(syn0)\n",
    "print('********** PESOS PARA CAPA DE SALIDA')\n",
    "print(syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe4b1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Pesos de capa 1\n",
      "[[ -1.75999634  -1.36601986  -3.2197858   -6.03370484  -1.85852437\n",
      "   -1.68664948  -2.54566663  -2.68953606  -3.76784373  -1.19102015\n",
      "   -1.24013553  -1.96835895  -2.12215514  -2.03480597  -1.90143827\n",
      "   -1.27060684  -1.40091141  -3.13117835  -3.23959135  -1.86765913\n",
      "   -1.17471068  -3.24062451  -1.21960817  -0.12310019   0.48716857\n",
      "   -2.94700976  -2.55685665  -2.69946054  -5.67898034  -0.60669912\n",
      "   -2.3296433   -1.8120565   -2.30902967  -1.89700272  -2.46350072\n",
      "   -1.60554595  -0.77019425  -0.47705309  -7.47703946  -0.88017481\n",
      "   -2.65918054  -1.78255914  -2.1622123   -1.07188769  -2.94546778\n",
      "   -4.14638378   3.12355587  -1.72958834  -1.85307564  -2.72644047\n",
      "   -3.13921339  -0.54658935]\n",
      " [ -1.45001246  -1.85799367   0.51860849 -10.14113573  -2.17189059\n",
      "   -2.48815053   0.06503355   0.1839559   -6.4816062   -1.49658704\n",
      "    4.04297647  -2.82437913  -1.39472963  -3.11429082  -1.86567713\n",
      "   -1.09955297  -0.40816499   0.49530954   0.53538509  -1.39122389\n",
      "   -2.30781842  -3.75115672  -1.67105365  -2.25799455  -1.10885731\n",
      "   -3.56098546   0.06637843  -2.95986711   9.55756432  -1.2621152\n",
      "   -2.60722017  -0.73242446  -3.2782149   -0.39326154  -3.13802922\n",
      "   -1.5840933   -1.39807724  -1.26712259  -6.91578915  -0.8590617\n",
      "   -3.19880883  -0.28378724  -0.32211035  -2.50212302   0.29426937\n",
      "    1.1317475   -6.12536653  -0.90558605  -0.82058698   0.15837873\n",
      "    2.38990102  -1.9254603 ]\n",
      " [ -0.59453988  -1.28176571  -3.25563126   2.94224613  -2.08003864\n",
      "   -1.45463189  -1.7958528   -2.71956563   7.26788645  -0.94441669\n",
      "   -0.08366533  -2.54449193  -0.73968289  -2.69791289  -1.91477022\n",
      "   -3.10636315  -1.64720316  -3.24476675  -2.62525401  -1.5067609\n",
      "   -1.10579168  -3.74040412  -1.47403166  -0.87652017  -2.12330497\n",
      "   -3.50229752  -1.01013226  -2.89295398  -7.38252871  -2.33071375\n",
      "   -2.58454267  -2.07435808  -2.9245083   -2.12059057  -2.93218582\n",
      "   -2.28976334  -1.63034204  -2.08303682  -6.22000419  -2.06829936\n",
      "   -3.32777054  -1.48106072  -1.81227206  -1.59298915  -1.6311179\n",
      "   -4.52816019  -6.06790792  -0.82050888  -0.98698077  -1.96169449\n",
      "    1.40781579  -1.28381057]\n",
      " [ -1.25406161  -0.63812926   0.33364462   5.04015478  -2.05197405\n",
      "   -2.19387653  -0.68194277  -0.10045073   4.35988728  -1.63269774\n",
      "    0.30561532  -2.55022925  -0.88897288  -3.02532025  -1.89730036\n",
      "    0.18639129  -1.44018074   0.2022117   -0.30643515  -0.29569627\n",
      "   -0.67480845  -3.41528805  -1.61685083  -1.6857828   -1.82339892\n",
      "   -3.2056674   -1.15103158  -2.76192345  -5.23041288  -0.84895173\n",
      "   -2.4556703   -0.28766274  -3.01817676  -0.5638891   -2.75234331\n",
      "   -2.93709402  -1.16719384  -1.02506693  10.04284641  -1.16085163\n",
      "   -2.96164838  -1.07740249  -0.53568132  -0.20952447  -0.82364513\n",
      "    0.99931611   4.27366534  -1.26271942  -1.02258998  -0.54012579\n",
      "   -2.47820081  -1.42706313]]\n",
      "********** Pesos de capa 2 (salida)\n",
      "[[ 7.02811593e-01]\n",
      " [ 4.92293148e-01]\n",
      " [ 2.74848102e+00]\n",
      " [ 1.08471120e+01]\n",
      " [-1.19059576e+00]\n",
      " [-1.02121745e+00]\n",
      " [ 1.86582430e+00]\n",
      " [ 2.14048233e+00]\n",
      " [-9.83788139e+00]\n",
      " [ 8.28519806e-02]\n",
      " [ 6.00993438e+00]\n",
      " [-2.34215321e+00]\n",
      " [ 1.00002264e+00]\n",
      " [-3.14453228e+00]\n",
      " [-7.78321195e-01]\n",
      " [ 1.43259816e+00]\n",
      " [ 5.84291720e-01]\n",
      " [ 2.73249503e+00]\n",
      " [ 2.60362490e+00]\n",
      " [ 1.23543710e+00]\n",
      " [ 1.43238767e-01]\n",
      " [-5.10853702e+00]\n",
      " [-3.26007012e-01]\n",
      " [-1.18878376e+00]\n",
      " [-1.33303953e+00]\n",
      " [-4.42800119e+00]\n",
      " [ 1.94937760e+00]\n",
      " [-2.82675434e+00]\n",
      " [-1.63845740e+01]\n",
      " [ 1.10936023e-02]\n",
      " [-2.08620594e+00]\n",
      " [ 1.35546688e+00]\n",
      " [-3.45429528e+00]\n",
      " [ 1.29217944e+00]\n",
      " [-3.04357448e+00]\n",
      " [-1.04674735e+00]\n",
      " [-1.76446123e-01]\n",
      " [-2.40160881e-01]\n",
      " [-1.72349008e+01]\n",
      " [ 1.09792428e-01]\n",
      " [-3.56472055e+00]\n",
      " [ 1.22908493e+00]\n",
      " [ 1.47737662e+00]\n",
      " [ 5.98311910e-01]\n",
      " [ 2.25405409e+00]\n",
      " [ 4.20661024e+00]\n",
      " [ 8.14089833e+00]\n",
      " [ 8.08226318e-01]\n",
      " [ 1.05833121e+00]\n",
      " [ 2.10252278e+00]\n",
      " [ 3.64210071e+00]\n",
      " [-6.87970459e-01]]\n",
      "********** Predicciones\n",
      "[[2.49629555e-04]\n",
      " [9.99811299e-01]\n",
      " [9.99687460e-01]\n",
      " [3.00413290e-04]\n",
      " [9.99759026e-01]\n",
      " [6.03779853e-05]\n",
      " [1.77805515e-04]\n",
      " [7.49577958e-01]\n",
      " [1.99592209e-01]\n",
      " [9.99451492e-01]\n",
      " [2.86829925e-04]\n",
      " [8.28593121e-04]\n",
      " [9.99433500e-01]\n",
      " [6.76624924e-04]\n",
      " [9.99972948e-01]\n",
      " [9.99324711e-01]\n",
      " [1.99592209e-01]\n",
      " [2.49629555e-04]\n",
      " [9.99811299e-01]\n",
      " [9.99687460e-01]\n",
      " [3.00413290e-04]\n",
      " [9.99759026e-01]\n",
      " [6.03779853e-05]\n",
      " [1.77805515e-04]\n",
      " [7.49577958e-01]\n",
      " [1.99592209e-01]\n",
      " [2.49629555e-04]\n",
      " [9.99811299e-01]\n",
      " [9.99687460e-01]\n",
      " [3.00413290e-04]\n",
      " [9.99759026e-01]\n",
      " [6.03779853e-05]\n",
      " [1.77805515e-04]\n",
      " [7.49577958e-01]\n",
      " [1.99592209e-01]\n",
      " [2.49629555e-04]\n",
      " [9.99811299e-01]\n",
      " [9.99687460e-01]\n",
      " [3.00413290e-04]\n",
      " [9.99759026e-01]\n",
      " [6.03779853e-05]\n",
      " [1.77805515e-04]\n",
      " [7.49577958e-01]\n",
      " [1.99592209e-01]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>real</th>\n",
       "      <th>predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  real  predicción\n",
       "0   0   0   0   0     0           0\n",
       "1   0   0   0   1     1           1\n",
       "2   0   0   1   0     1           1\n",
       "3   0   0   1   1     0           0\n",
       "4   0   1   0   0     1           1\n",
       "5   0   1   0   1     0           0\n",
       "6   0   1   1   0     0           0\n",
       "7   0   1   1   1     1           1\n",
       "8   1   1   1   1     0           0\n",
       "9   1   0   0   0     1           1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "\n",
    "for j in range(2000000):#cantidad de epochs (un epoch es una pasada de forwarding y backpropagation)\n",
    "    \n",
    "    #1. Forward Propagation: \n",
    "    #producto punto de nuestros datos por nuestros pesos (Suma Ponderada) y lo pasamos por nuestra función de activación.\n",
    "    #Y para la siguiente capa multiplicamos los valores de la capa anterior y nuestra capa de pesos de la segunda capa. \n",
    "    #A esto nos referimos a que están cada una de las neuronas de la capa anterior conectadas con las neuronas \n",
    "    #de la capa siguiente.\n",
    "\n",
    "    l0 = X\n",
    "    #print('********** X')\n",
    "    #print(l0)\n",
    "    l1 = sigmoid(np.dot(l0,syn0)) #np.dot(l0,syn0) es z  \n",
    "    #print('********** Salidas de capa 1')\n",
    "    #print(l1)\n",
    "    l2 = sigmoid(np.dot(l1,syn1)) #Estas son las predicciones\n",
    "    #print('********** Salidas de capa 2 (salida)')\n",
    "    #print(l2)\n",
    "    \n",
    "    #2. Calculo del Error: entre predicciones actuales y reales para determinar la Función de Pérdida\n",
    "    l2_error = y - l2\n",
    "    #print('********** Errores en capa de salida')\n",
    "    #print(l2_error)     \n",
    "    \n",
    "    #Algoritmo de Descenso de Gradiente: la pendiente (la tasa de cambio) se calcula multiplicando nuestra perdida actual \n",
    "    #con la derivada de nuestras predicciones actuales, de esta manera vamos a saber para que dirección ajustar los pesos.\n",
    "    \n",
    "    l2_delta = l2_error*derivada(l2) #es la pendiente (direcciones hacia donde mover pesos). \n",
    "    #n (tasa de aprendizaje) es 1. l2 son las predicciones actuales, es decir, las entradas X de la capa actual.\n",
    "    #print('********** Gradiente en capa de salida')\n",
    "    #print(l2_delta)\n",
    "    \n",
    "    #3. Backpropagation: propagar el error hacia atrás -> \"la dirección hacia donde moveremos los pesos de la ultima capa\"\n",
    "    \n",
    "    #multiplicar la pendiente \"l2_delta\" por la transpuesta de los pesos de la capa anterior \"syn1.T\", de este modo \n",
    "    #propagaremos el error hacia atrás, y de esta manera la capa anterior \"l1\" calculará la dirección \"l1_delta\" hacia \n",
    "    #donde debe mover los pesos \"syn1\" y \"syn0\".\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    #print('********** Errores en capa 1')\n",
    "    #print(l1_error)\n",
    "    l1_delta = l1_error * derivada(l1)\n",
    "    #print('********** Gradiente en capa 1')\n",
    "    #print(l1_delta)\n",
    "    \n",
    "    #Finalmente, ajustamos el valor de nuestros pesos, multiplicando la transpuesta de la capa por sus respectivas \n",
    "    #optimizaciones, o direcciones hacia donde actualizar los pesos, y esto se suma a nuestros pesos actuales, \n",
    "    #actualizando las dos capas a la vez.\n",
    "    \n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    \n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "print('********** Pesos de capa 1')\n",
    "print(syn0)\n",
    "print('********** Pesos de capa 2 (salida)')\n",
    "print(syn1)\n",
    "print('********** Predicciones')\n",
    "print(l2)\n",
    "\n",
    "#Se presenta las entradas, los valores reales y predicciones\n",
    "#Se forma un dataframe con X\n",
    "df = pd.DataFrame(X, columns = ['X1','X2','X3','X4'])\n",
    "df.head()\n",
    "y_pred = (l2 >= 0.5).astype(\"int32\")\n",
    "y_pred = y_pred.flatten()# de 2D a 1D\n",
    "y_real=y.flatten()\n",
    "#Se forma un dataframe con los valores reales y predicciones\n",
    "dataframeSalida=pd.DataFrame({'real':y_real, 'predicción': y_pred})\n",
    "dataframeSalida.head()\n",
    "#Se concatena los dataframes de X y los valores reales y de predicción, esto con respecto al eje 1 (columnas)\n",
    "df=pd.concat([df, dataframeSalida], axis=1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bc0df",
   "metadata": {},
   "source": [
    "<h4> Resultados y Conclusiones</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c9c47",
   "metadata": {},
   "source": [
    "<ul>\n",
    "   \n",
    "<li>La lógica de la compuerta XOR cuando las entradas estan activas=1 en número impar se tiene una salida de 1 y cuando el número es par se tiene una salida de 0 </li>\n",
    "<li>En la Red Neuronal para que la predicción sea más precisa a la real se puede recomendar repetir dos veces las mismas filas para que aprenda de mejor manera, en mi caso puse cinco veces de la tabla de verdad para llegar a un mejor resultado al aumentar neuronas.</li>\n",
    "<li>Al momento que empezamos aumentar las neuronas, puede llegar a confundirse y tener mayor error en la predicción. Para solucionar esto hay que aumentar las veces de forwarding y backpropagation.</li>\n",
    "<li>Puedo concluir que al momento de aprendizaje es mejor empezar desde un número bajo de neuronas y ir subiendo poco a poco para evitar que haya errores en la predicción</li>\n",
    "<li>En mi caso para tener el resultado Real y la Predicción correctamente, logré llegar hasta las 52 neuronas  que fuerón suficientes para que la predicción sea correcta </li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
