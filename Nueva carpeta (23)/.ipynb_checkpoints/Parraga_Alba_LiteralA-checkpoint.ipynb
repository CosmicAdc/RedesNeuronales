{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d49286",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b0/Logo_Universidad_Politécnica_Salesiana_del_Ecuador.png\" width=\"90%\">\n",
    "<h2>Práctica 1:\n",
    "    Redes neuronale</h2>\n",
    "<h3>Integrantes: Michelle Parraga, Andrés Alba </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f365740b",
   "metadata": {},
   "source": [
    "a) modificar el cuaderno de tal manera que la red neuronal pueda aprender la compuerta NAND con 4 entradas.\n",
    "La primera capa debe tener 64 neuronas y la segunda capa 1 neurona. Mostrar como salida el dataframe con las \n",
    "columnas: “predicción” y “real”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f42b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6032e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#COMPUERTA NAND DE CUATRO ENTRADAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset: Entradas\n",
    "X = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 1],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 1, 1],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 1, 0, 1],\n",
    "              [0, 1, 1, 0],\n",
    "              [0, 1, 1, 1],\n",
    "              [1, 1, 1, 1],#\n",
    "              [1, 0, 0, 0],\n",
    "              [1, 0, 0, 1],\n",
    "              [1, 0, 1, 0],\n",
    "              [1, 0, 1, 1],\n",
    "              [1, 1, 0, 0],\n",
    "              [1, 1, 0, 1],\n",
    "              [1, 1, 1, 0],\n",
    "              [1, 1, 1, 1],\n",
    "              ])#26\n",
    "\n",
    "# Salidas reales -> Aprendizaje Supervisado\n",
    "y = np.array([[1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "79acecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\" función sigmoide \"\"\"\n",
    "    fz=1/(1+np.exp(-z))\n",
    "    return fz\n",
    "\n",
    "def derivada(fz):\n",
    "    \"\"\" derivada de la función sigmoide \"\"\"\n",
    "    return fz*(1-fz)\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\" función tangente hiperbólica \"\"\"\n",
    "    return np.tanh(x)\n",
    " \n",
    "def tanh_derivada(x):\n",
    "    \"\"\" derivada de la función tangente hiperbólica \"\"\"\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2515848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** ENTRADAS\n",
      "[[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]]\n",
      "********** PESOS PARA CAPA DE ENTRADA\n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822 -0.81532281\n",
      "  -0.62747958 -0.30887855 -0.20646505  0.07763347 -0.16161097  0.370439\n",
      "  -0.5910955   0.75623487 -0.94522481  0.34093502 -0.1653904   0.11737966\n",
      "  -0.71922612 -0.60379702  0.60148914  0.93652315 -0.37315164  0.38464523\n",
      "   0.7527783   0.78921333 -0.82991158 -0.92189043 -0.66033916  0.75628501\n",
      "  -0.80330633 -0.15778475  0.91577906  0.06633057  0.38375423 -0.36896874\n",
      "   0.37300186  0.66925134 -0.96342345  0.50028863  0.97772218  0.49633131\n",
      "  -0.43911202]\n",
      " [ 0.57855866 -0.79354799 -0.10421295  0.81719101 -0.4127717  -0.42444932\n",
      "  -0.73994286 -0.96126608  0.35767107 -0.57674377 -0.46890668 -0.01685368\n",
      "  -0.89327491  0.14823521 -0.70654285  0.17861107  0.39951672 -0.79533114\n",
      "  -0.17188802  0.38880032 -0.17164146 -0.90009308  0.07179281  0.32758929\n",
      "   0.02977822  0.88918951  0.17311008  0.80680383 -0.72505059 -0.72144731\n",
      "   0.61478258 -0.20464633 -0.66929161  0.85501716 -0.30446828  0.50162421\n",
      "   0.45199597  0.76661218  0.24734441  0.50188487 -0.30220332 -0.46014422\n",
      "   0.79177244]\n",
      " [-0.14381762  0.92968009  0.326883    0.24339144 -0.77050805  0.89897852\n",
      "  -0.10017573  0.15677923 -0.18372639 -0.52594604  0.80675904  0.14735897\n",
      "  -0.99425935  0.23428983 -0.3467102   0.0541162   0.7718842  -0.28546048\n",
      "   0.8170703   0.24672023 -0.96835751  0.85887447  0.38179384  0.9946457\n",
      "  -0.65531898 -0.7257285   0.86519093  0.39363632 -0.86799965  0.51092611\n",
      "   0.50775238  0.84604907  0.42304952 -0.75145808 -0.96023973 -0.94757803\n",
      "  -0.94338702 -0.50757786  0.7200559   0.07766213  0.10564396  0.68406178\n",
      "  -0.75165337]\n",
      " [-0.44163264  0.17151854  0.9391915   0.12206044 -0.96270542  0.60126535\n",
      "  -0.53405145  0.61421039 -0.22427871  0.72708371  0.49424329  0.11248047\n",
      "  -0.72708955 -0.88016462 -0.75731309 -0.91089624 -0.78501174 -0.54858132\n",
      "   0.42597796  0.11943396 -0.97488804 -0.85605144  0.93455266  0.13620092\n",
      "  -0.59341353 -0.49534851  0.48765171 -0.60914104  0.16271785  0.94003998\n",
      "   0.6936576  -0.52030448 -0.01246057  0.23991144  0.6579618  -0.68641721\n",
      "  -0.9628476  -0.85995571 -0.02730978  0.21265892  0.13770287 -0.36527518\n",
      "   0.97723231]]\n",
      "********** PESOS PARA CAPA DE SALIDA\n",
      "[[ 0.15949044]\n",
      " [-0.23971765]\n",
      " [ 0.10189644]\n",
      " [ 0.49066886]\n",
      " [ 0.33846579]\n",
      " [-0.47016088]\n",
      " [-0.86733033]\n",
      " [-0.2598316 ]\n",
      " [ 0.25943501]\n",
      " [-0.57965198]\n",
      " [ 0.50551111]\n",
      " [-0.86692704]\n",
      " [-0.4793698 ]\n",
      " [ 0.60950913]\n",
      " [-0.61313143]\n",
      " [ 0.27892176]\n",
      " [ 0.04934062]\n",
      " [ 0.84961594]\n",
      " [-0.47340646]\n",
      " [-0.86807782]\n",
      " [ 0.47013193]\n",
      " [ 0.54435606]\n",
      " [ 0.81563171]\n",
      " [ 0.86394414]\n",
      " [-0.97209685]\n",
      " [-0.53127583]\n",
      " [ 0.23355671]\n",
      " [ 0.89803264]\n",
      " [ 0.90035224]\n",
      " [ 0.11330638]\n",
      " [ 0.8312127 ]\n",
      " [ 0.28313242]\n",
      " [-0.21998457]\n",
      " [-0.02801867]\n",
      " [ 0.20862097]\n",
      " [ 0.09909584]\n",
      " [ 0.85236285]\n",
      " [ 0.83746687]\n",
      " [-0.21024877]\n",
      " [ 0.92652506]\n",
      " [-0.65208867]\n",
      " [-0.74734096]\n",
      " [-0.72984168]]\n"
     ]
    }
   ],
   "source": [
    "# Construcción\n",
    "\n",
    "#Como paso opcional, definimos una seed (semilla), para tener los mismo resultados, e inicializamos de forma aleatoria los pesos.\n",
    "#La primera matriz de pesos tiene que ser de un tamaño fijo, en este caso (2,3) porque tenemos 2 valores de entrada \n",
    "#(es decir, 2 variables o características) y la siguiente capa tiene 3, entonces la salida tiene que tener la misma cantidad \n",
    "#de entradas que tiene la siguiente capa.\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#syn0=np.array([[0.1,0.3,0.5],\n",
    "#               [0.2,0.4,0.6]])\n",
    "#syn1=np.array([[0.7],\n",
    "#               [0.9],\n",
    "#               [0.11]])\n",
    "\n",
    "syn0 = 2*np.random.random((4,43)) - 1\n",
    "syn1 = 2*np.random.random((43,1)) - 1\n",
    "\n",
    "print('********** ENTRADAS')\n",
    "print(X)\n",
    "print('********** PESOS PARA CAPA DE ENTRADA')\n",
    "print(syn0)\n",
    "print('********** PESOS PARA CAPA DE SALIDA')\n",
    "print(syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63b8f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Pesos de capa 1\n",
      "[[-0.68467322  0.65150782 -2.33356458 -1.50186384 -0.436698   -0.69625814\n",
      "  -0.64140814 -0.90876804 -0.7449777  -0.21315595 -1.30897971  0.88004312\n",
      "  -0.2877078   1.05880319 -0.86124429  0.38413263 -0.86198626  1.1867324\n",
      "  -0.70649369 -0.95419543  2.11829056  1.77677323 -1.81640417 -0.44080919\n",
      "   1.84630368  1.94178939 -2.06593087 -2.75864881 -0.78581284  0.68072255\n",
      "  -2.60609644 -0.76319762  0.53463722 -0.54822059  0.64583754 -0.41548541\n",
      "   1.53121958  1.33421825 -1.8020654  -0.06652008  1.86329072  1.31358475\n",
      "  -0.82826772]\n",
      " [ 0.69274448 -0.77830264 -0.99286525  0.58794707  0.17357241 -0.09458987\n",
      "  -0.69961173 -1.99147906  0.35922034 -1.0764281  -1.98698775  0.320639\n",
      "  -0.65597156 -0.59517379 -0.49195396 -0.07503012  0.05167698 -2.30394838\n",
      "   0.19602565  1.39364517  0.01342186 -2.942081   -1.21030203 -0.58402677\n",
      "   1.05715776  2.1592904  -0.62192467  1.68597153 -1.56745091 -0.9302813\n",
      "  -0.02535308 -0.98992685 -1.09667772  0.65972348 -1.46561901  1.41739699\n",
      "   1.45624029  1.30463675 -0.08903086 -0.3149736  -0.42375445 -0.47344743\n",
      "   2.17369904]\n",
      " [-0.69289618  1.16166966  0.0519404  -0.44059424 -0.65786918  1.39103386\n",
      "   0.05979159  0.0611574  -0.76930958 -1.08282261  0.91043831  0.51847746\n",
      "  -0.82017143 -0.22568515 -0.06338508 -0.30368702  0.62296124 -0.32174329\n",
      "   1.38540639  1.01319016 -2.20044657  1.57767827 -0.2076716   0.20379167\n",
      "  -0.42973666 -1.19800483  0.65337098  0.89638119 -1.78050489  0.43375798\n",
      "  -0.14029391  1.33325273  0.01890208 -1.6504303  -2.49696718 -1.78593661\n",
      "  -2.75027916 -2.28471398  0.57875551 -1.02051424  0.34944764  1.67914102\n",
      "  -1.40020529]\n",
      " [-1.0160249   0.28625708  1.39402892 -0.39859156 -0.81751916  0.97195961\n",
      "  -0.54494979  1.01884523 -0.55369628  0.70901254  0.55343158 -0.02138608\n",
      "  -0.4569221  -2.1536128  -0.6045091  -1.91191352 -1.6035443  -0.49264969\n",
      "   0.77977295  0.25831043 -1.75539765 -2.55319272  1.52122637 -0.57906686\n",
      "  -0.67264856 -1.01498543  0.15125785 -1.85252977  2.54339029  0.8456686\n",
      "   0.69421338 -1.24638822 -0.47036684 -0.21582782  1.38772282 -0.94612091\n",
      "  -2.29578703 -2.33446404 -0.50183023 -0.32534213  0.05303535 -0.75929867\n",
      "   1.98205207]]\n",
      "********** Pesos de capa 2 (salida)\n",
      "[[ 2.11281061]\n",
      " [-0.84259574]\n",
      " [ 2.89564063]\n",
      " [ 2.15312188]\n",
      " [ 2.39189605]\n",
      " [-1.11703537]\n",
      " [ 1.40257632]\n",
      " [ 2.55705478]\n",
      " [ 2.18782813]\n",
      " [ 1.70077667]\n",
      " [ 2.88616159]\n",
      " [-1.94646015]\n",
      " [ 1.30001573]\n",
      " [ 2.82491657]\n",
      " [ 1.36079993]\n",
      " [ 2.41489627]\n",
      " [ 1.85772325]\n",
      " [ 3.51528275]\n",
      " [-1.36708809]\n",
      " [-2.22942962]\n",
      " [ 3.66282057]\n",
      " [ 4.27663909]\n",
      " [ 3.09024104]\n",
      " [ 1.00961834]\n",
      " [-2.19910057]\n",
      " [-2.92329094]\n",
      " [ 2.25939749]\n",
      " [ 3.97889102]\n",
      " [ 4.14167287]\n",
      " [-0.578421  ]\n",
      " [ 3.01343607]\n",
      " [ 2.54901465]\n",
      " [ 0.57663024]\n",
      " [ 1.77896046]\n",
      " [ 3.37568775]\n",
      " [ 2.79144046]\n",
      " [ 4.23839694]\n",
      " [ 3.78430694]\n",
      " [ 1.80054338]\n",
      " [ 2.16912722]\n",
      " [-2.15009427]\n",
      " [-2.33847424]\n",
      " [-2.99477972]]\n",
      "********** Predicciones\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999991]\n",
      " [1.        ]\n",
      " [0.99999969]\n",
      " [0.99998955]\n",
      " [0.9987592 ]\n",
      " [0.00172449]\n",
      " [1.        ]\n",
      " [0.99999908]\n",
      " [0.99999539]\n",
      " [0.99877194]\n",
      " [0.99999946]\n",
      " [0.99875093]\n",
      " [0.99881078]\n",
      " [0.00172449]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>real</th>\n",
       "      <th>predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1  X2  X3  X4  real  predicción\n",
       "0    0   0   0   0     1           1\n",
       "1    0   0   0   1     1           1\n",
       "2    0   0   1   0     1           1\n",
       "3    0   0   1   1     1           1\n",
       "4    0   1   0   0     1           1\n",
       "5    0   1   0   1     1           1\n",
       "6    0   1   1   0     1           1\n",
       "7    0   1   1   1     1           1\n",
       "8    1   1   1   1     0           0\n",
       "9    1   0   0   0     1           1\n",
       "10   1   0   0   1     1           1\n",
       "11   1   0   1   0     1           1\n",
       "12   1   0   1   1     1           1\n",
       "13   1   1   0   0     1           1\n",
       "14   1   1   0   1     1           1\n",
       "15   1   1   1   0     1           1\n",
       "16   1   1   1   1     0           0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "\n",
    "for j in range(200000):#cantidad de epochs (un epoch es una pasada de forwarding y backpropagation)\n",
    "    \n",
    "    #1. Forward Propagation: \n",
    "    #producto punto de nuestros datos por nuestros pesos (Suma Ponderada) y lo pasamos por nuestra función de activación.\n",
    "    #Y para la siguiente capa multiplicamos los valores de la capa anterior y nuestra capa de pesos de la segunda capa. \n",
    "    #A esto nos referimos a que están cada una de las neuronas de la capa anterior conectadas con las neuronas \n",
    "    #de la capa siguiente.\n",
    "\n",
    "    l0 = X\n",
    "    #print('********** X')\n",
    "    #print(l0)\n",
    "    l1 = sigmoid(np.dot(l0,syn0)) #np.dot(l0,syn0) es z  \n",
    "    #print('********** Salidas de capa 1')\n",
    "    #print(l1)\n",
    "    l2 = sigmoid(np.dot(l1,syn1)) #Estas son las predicciones\n",
    "    #print('********** Salidas de capa 2 (salida)')\n",
    "    #print(l2)\n",
    "    \n",
    "    #2. Calculo del Error: entre predicciones actuales y reales para determinar la Función de Pérdida\n",
    "    l2_error = y - l2\n",
    "    #print('********** Errores en capa de salida')\n",
    "    #print(l2_error)     \n",
    "    \n",
    "    #Algoritmo de Descenso de Gradiente: la pendiente (la tasa de cambio) se calcula multiplicando nuestra perdida actual \n",
    "    #con la derivada de nuestras predicciones actuales, de esta manera vamos a saber para que dirección ajustar los pesos.\n",
    "    \n",
    "    l2_delta = l2_error*derivada(l2) #es la pendiente (direcciones hacia donde mover pesos). \n",
    "    #n (tasa de aprendizaje) es 1. l2 son las predicciones actuales, es decir, las entradas X de la capa actual.\n",
    "    #print('********** Gradiente en capa de salida')\n",
    "    #print(l2_delta)\n",
    "    \n",
    "    #3. Backpropagation: propagar el error hacia atrás -> \"la dirección hacia donde moveremos los pesos de la ultima capa\"\n",
    "    \n",
    "    #multiplicar la pendiente \"l2_delta\" por la transpuesta de los pesos de la capa anterior \"syn1.T\", de este modo \n",
    "    #propagaremos el error hacia atrás, y de esta manera la capa anterior \"l1\" calculará la dirección \"l1_delta\" hacia \n",
    "    #donde debe mover los pesos \"syn1\" y \"syn0\".\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    #print('********** Errores en capa 1')\n",
    "    #print(l1_error)\n",
    "    l1_delta = l1_error * derivada(l1)\n",
    "    #print('********** Gradiente en capa 1')\n",
    "    #print(l1_delta)\n",
    "    \n",
    "    #Finalmente, ajustamos el valor de nuestros pesos, multiplicando la transpuesta de la capa por sus respectivas \n",
    "    #optimizaciones, o direcciones hacia donde actualizar los pesos, y esto se suma a nuestros pesos actuales, \n",
    "    #actualizando las dos capas a la vez.\n",
    "    \n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    \n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "print('********** Pesos de capa 1')\n",
    "print(syn0)\n",
    "print('********** Pesos de capa 2 (salida)')\n",
    "print(syn1)\n",
    "print('********** Predicciones')\n",
    "print(l2)\n",
    "\n",
    "#Se presenta las entradas, los valores reales y predicciones\n",
    "#Se forma un dataframe con X\n",
    "df = pd.DataFrame(X, columns = ['X1','X2','X3','X4'])\n",
    "df.head()\n",
    "y_pred = (l2 >= 0.5).astype(\"int32\")\n",
    "y_pred = y_pred.flatten()# de 2D a 1D\n",
    "y_real=y.flatten()\n",
    "#Se forma un dataframe con los valores reales y predicciones\n",
    "dataframeSalida=pd.DataFrame({'real':y_real, 'predicción': y_pred})\n",
    "dataframeSalida.head()\n",
    "#Se concatena los dataframes de X y los valores reales y de predicción, esto con respecto al eje 1 (columnas)\n",
    "df=pd.concat([df, dataframeSalida], axis=1)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95575fdc",
   "metadata": {},
   "source": [
    "<h4> Resultados y Conclusiones</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406baa63",
   "metadata": {},
   "source": [
    "<ul>\n",
    "   \n",
    "<li>La lógica de la compuerta NAND  tiene una sola salida falsa \"0\" solamente si todas sus entradas son verdaderas \"1\"  </li>\n",
    " <li>En este caso usamos 4 entradas que la salida es falsa=0 si las cuatro entradas son verdaderas=1</li>\n",
    "<li>En la Red Neuronal para que la predicción sea más precisa a la real se puede recomendar repetir dos veces la misma fila para que aprenda de mejor manera.</li>\n",
    "<li>Al momento que empezamos aumentar las neuronas, puede llegar a confundirse y tener mayor error en la predicción. Para solucionar esto hay que aumentar las veces de forwarding y backpropagation.</li>\n",
    "<li>Puedo concluir que al momento de aprendizaje es mejor empezar desde un número bajo de neuronas y ir subiendo poco a poco para evitar que haya errores en la predicción</li>\n",
    "<li>En mi caso para tener el resultado Real y la Predicción correctamente, logré llegar hasta las 43 neuronas que son suficientes para tener la predicción correcta </li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
